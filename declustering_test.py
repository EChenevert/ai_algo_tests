# Remeber that some of the sites within the dataset i imported are missing lat long values...
# Will have to reimport later
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt



# Wrappers and functions
# utility to convert GSLIB Geo-EAS files to a pandas DataFrame for use with Python methods
def GSLIB2Dataframe(data_file):
    import os
    import numpy as np
    import pandas as pd

    colArray = []
    with open(data_file) as myfile:  # read first two lines
        head = [next(myfile) for x in range(2)]
        line2 = head[1].split()
        ncol = int(line2[0])
        for icol in range(0, ncol):
            head = [next(myfile) for x in range(1)]
            colArray.append(head[0].split()[0])
        data = np.loadtxt(myfile, skiprows=0)
        df = pd.DataFrame(data)
        df.columns = colArray
        return df


# utility to convert GSLIB Geo-EAS files to a numpy ndarray for use with Python methods
def GSLIB2ndarray(data_file, kcol, nx, ny):
    import os
    import numpy as np

    colArray = []
    array = np.ndarray(shape=(nx, ny), dtype=float, order='F')
    with open(data_file) as myfile:  # read first two lines
        head = [next(myfile) for x in range(2)]
        line2 = head[1].split()
        ncol = int(line2[0])  # get the number of columns
        for icol in range(0, ncol):  # read over the column names
            head = [next(myfile) for x in range(1)]
            if icol == kcol:
                col_name = head[0].split()[0]
        for iy in range(0, ny):
            for ix in range(0, nx):
                head = [next(myfile) for x in range(1)]
                array[ny - 1 - iy][ix] = head[0].split()[kcol]
    return array, col_name


# histogram, reimplemented in Python of GSLIB hist with MatPlotLib methods
def hist(array, xmin, xmax, log, cumul, bins, weights, xlabel, title):
    plt.figure(figsize=(8, 6))
    cs = plt.hist(array, alpha=0.2, color='red', edgecolor='black', bins=bins, range=[xmin, xmax], weights=weights,
                  log=log, cumulative=cumul)
    plt.title(title)
    plt.xlabel(xlabel);
    plt.ylabel('Frequency')
    plt.show()
    return


# pixelplt, reimplemention in Python of GSLIB pixelplt with MatPlotLib methods
def pixelplt(array, xmin, xmax, ymin, ymax, step, vmin, vmax, title, xlabel, ylabel, vlabel, cmap):
    xx, yy = np.meshgrid(np.arange(xmin, xmax, step), np.arange(ymax, ymin, -1 * step))
    ixy = 0
    plt.figure(figsize=(8, 6))
    x = [];
    y = [];
    v = []  # use dummy since scatter plot controls legend min and max appropriately and contour does not!
    cs = plt.contourf(xx, yy, array, cmap=cmap, vmin=vmin, vmax=vmax)
    im = plt.scatter(x, y, s=None, c=v, marker=None, cmap=cmap, norm=None, vmin=vmin, vmax=vmax, alpha=0.8,
                     linewidths=0.8, verts=None, edgecolors="black")
    plt.title(title)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    # plt.clim(vmin,vmax)
    cbar = plt.colorbar(im, orientation='vertical')
    cbar.set_label(vlabel, rotation=270, labelpad=20)

    plt.show()
    return cs


# location map, reimplemention in Python of GSLIB locmap with MatPlotLib methods
def locmap(df, xcol, ycol, vcol, xmin, xmax, ymin, ymax, vmin, vmax, title, xlabel, ylabel, vlabel, cmap):
    ixy = 0
    plt.figure(figsize=(8, 6))
    im = plt.scatter(df[xcol], df[ycol], s=None, c=df[vcol], marker=None, cmap=cmap, norm=None, vmin=vmin, vmax=vmax,
                     alpha=0.8, linewidths=0.8, verts=None, edgecolors="black")
    plt.title(title)
    plt.xlim(xmin, xmax)
    plt.ylim(ymin, ymax)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    cbar = plt.colorbar(im, orientation='vertical')
    cbar.set_label(vlabel, rotation=270, labelpad=20)
    plt.show()
    return im


# pixelplt with location map superimposed, reimplementation in Python of a MOD from GSLIB with MatPlotLib methods
def locpix(array, xmin, xmax, ymin, ymax, step, vmin, vmax, df, xcol, ycol, vcol, title, xlabel, ylabel, vlabel, cmap):
    xx, yy = np.meshgrid(np.arange(xmin, xmax, step), np.arange(ymax, ymin, -1 * step))
    ixy = 0
    plt.figure(figsize=(8, 6))
    cs = plt.contourf(xx, yy, array, cmap=cmap, vmin=vmin, vmax=vmax)
    im = plt.scatter(df[xcol], df[ycol], s=None, c=df[vcol], marker=None, cmap=cmap, norm=None, vmin=vmin, vmax=vmax,
                     alpha=0.8, linewidths=0.8, verts=None, edgecolors="black")
    plt.title(title)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    cbar = plt.colorbar(orientation='vertical')
    cbar.set_label(vlabel, rotation=270, labelpad=20)
    plt.show()
    return cs


# affine distribution correction reimplemented in Python with numpy methods
def affine(array, tmean, tstdev):
    if array.ndim != 2:
        print("Error: must use a 2D array")
        return
    nx = array.shape[0]
    ny = array.shape[1]
    mean = np.average(array)
    stdev = np.std(array)
    for iy in range(0, ny):
        for ix in range(0, nx):
            array[ix, iy] = (tstdev / stdev) * (array[ix, iy] - mean) + tmean
    return (array)


# normal score transform, wrapper for nscore from GSLIB (.exe must be in working directory)(not used in this demo)
def nscore(x, y):
    import os
    import numpy as np
    nx = len(x)
    file = 'nscore_out.dat'
    file_out = open(file, "w")
    file_out.write('nscore_out.dat' + '\n')
    file_out.write('1' + '\n')
    file_out.write('nscore_out' + '\n')
    for ix in range(0, nx - 1):
        file_out.write(str(x[ix]) + '\n')
    file_out.close()

    file = open("nscore.par", "w")
    file.write("                  Parameters for NSCORE                                    \n")
    file.write("                  *********************                                    \n")
    file.write("                                                                           \n")
    file.write("START OF PARAMETERS:                                                       \n")
    file.write("nscore_out.dat           -file with data                                   \n")
    file.write("1   0                    -  columns for variable and weight                \n")
    file.write("-1.0e21   1.0e21         -  trimming limits                                \n")
    file.write("0                        -1=transform according to specified ref. dist.    \n")
    file.write("../histsmth/histsmth.out -  file with reference dist.                      \n")
    file.write("1   2                    -  columns for variable and weight                \n")
    file.write("nscore.out               -file for output                                  \n")
    file.write("nscore.trn               -file for output transformation table             \n")
    file.close()

    os.system('nscore.exe nscore.par')
    file_in = 'nscore.out'
    with open(file_in) as myfile:  # read first two lines
        head = [next(myfile) for x in range(2)]
        ncol = int(head[1][:-1])  # number of columns
        data = np.loadtxt(file_in, skiprows=2 + ncol)

    number_values = len(data)  # gives nx - 1
    for ix in range(0, number_values):
        y[ix] = data[ix, 1]


# cell-based declustering, 2D wrapper for declus from GSLIB (.exe must be in working directory)
def declus(df, xcol, ycol, vcol, cmin, cmax, cnum, bmin):
    import os
    import numpy as np
    nrow = len(df)
    weights = []
    file = 'declus_out.dat'
    file_out = open(file, "w")
    file_out.write('declus_out.dat' + '\n')
    file_out.write('3' + '\n')
    file_out.write('x' + '\n')
    file_out.write('y' + '\n')
    file_out.write('value' + '\n')
    for irow in range(0, nrow):
        file_out.write(
            str(df.iloc[irow][xcol]) + ' ' + str(df.iloc[irow][ycol]) + ' ' + str(df.iloc[irow][vcol]) + ' \n')
    file_out.close()

    file = open("declus.par", "w")
    file.write("                  Parameters for DECLUS                                    \n")
    file.write("                  *********************                                    \n")
    file.write("                                                                           \n")
    file.write("START OF PARAMETERS:                                                       \n")
    file.write("declus_out.dat           -file with data                                   \n")
    file.write("1   2   0   3               -  columns for X, Y, Z, and variable           \n")
    file.write("-1.0e21     1.0e21          -  trimming limits                             \n")
    file.write("declus.sum                  -file for summary output                       \n")
    file.write("declus.out                  -file for output with data & weights           \n")
    file.write("1.0   1.0                   -Y and Z cell anisotropy (Ysize=size*Yanis)    \n")
    file.write(str(bmin) + "                -0=look for minimum declustered mean (1=max)   \n")
    file.write(str(cnum) + " " + str(cmin) + " " + str(cmax) + " -number of cell sizes, min size, max size      \n")
    file.write("5                           -number of origin offsets                      \n")
    file.close()

    os.system('declus.exe declus.par')
    df = GSLIB2Dataframe("declus.out")
    for irow in range(0, nrow):
        weights.append(df.iloc[irow, 3])

    return (weights)


# sequential Gaussian simulation, 2D unconditional wrapper for sgsim from GSLIB (.exe must be in working directory)
def GSLIB_sgsim_2d_uncond(nreal, nx, ny, hsiz, seed, hrange1, hrange2, azi, output_file):
    import os
    import numpy as np

    hmn = hsiz * 0.5
    hctab = int(hrange1 / hsiz) * 2 + 1

    sim_array = np.random.rand(nx, ny)

    file = open("sgsim.par", "w")
    file.write("              Parameters for SGSIM                                         \n")
    file.write("              ********************                                         \n")
    file.write("                                                                           \n")
    file.write("START OF PARAMETER:                                                        \n")
    file.write("none                          -file with data                              \n")
    file.write("1  2  0  3  5  0              -  columns for X,Y,Z,vr,wt,sec.var.          \n")
    file.write("-1.0e21 1.0e21                -  trimming limits                           \n")
    file.write("0                             -transform the data (0=no, 1=yes)            \n")
    file.write("none.trn                      -  file for output trans table               \n")
    file.write("1                             -  consider ref. dist (0=no, 1=yes)          \n")
    file.write("none.dat                      -  file with ref. dist distribution          \n")
    file.write("1  0                          -  columns for vr and wt                     \n")
    file.write("-4.0    4.0                   -  zmin,zmax(tail extrapolation)             \n")
    file.write("1      -4.0                   -  lower tail option, parameter              \n")
    file.write("1       4.0                   -  upper tail option, parameter              \n")
    file.write("0                             -debugging level: 0,1,2,3                    \n")
    file.write("nonw.dbg                      -file for debugging output                   \n")
    file.write(str(output_file) + "           -file for simulation output                  \n")
    file.write(str(nreal) + "                 -number of realizations to generate          \n")
    file.write(str(nx) + " " + str(hmn) + " " + str(hsiz) + "                              \n")
    file.write(str(ny) + " " + str(hmn) + " " + str(hsiz) + "                              \n")
    file.write("1 0.0 1.0                     - nz zmn zsiz                                \n")
    file.write(str(seed) + "                  -random number seed                          \n")
    file.write("0     8                       -min and max original data for sim           \n")
    file.write("12                            -number of simulated nodes to use            \n")
    file.write("0                             -assign data to nodes (0=no, 1=yes)          \n")
    file.write("1     3                       -multiple grid search (0=no, 1=yes),num      \n")
    file.write("0                             -maximum data per octant (0=not used)        \n")
    file.write(str(hrange1) + " " + str(hrange2) + " 1.0 -maximum search  (hmax,hmin,vert) \n")
    file.write(str(azi) + "   0.0   0.0       -angles for search ellipsoid                 \n")
    file.write(str(hctab) + " " + str(hctab) + " 1 -size of covariance lookup table        \n")
    file.write("0     0.60   1.0              -ktype: 0=SK,1=OK,2=LVM,3=EXDR,4=COLC        \n")
    file.write("none.dat                      -  file with LVM, EXDR, or COLC variable     \n")
    file.write("4                             -  column for secondary variable             \n")
    file.write("1    0.0                      -nst, nugget effect                          \n")
    file.write("1    1.0 " + str(azi) + " 0.0 0.0 -it,cc,ang1,ang2,ang3                    \n")
    file.write(" " + str(hrange1) + " " + str(hrange2) + " 1.0 -a_hmax, a_hmin, a_vert     \n")
    file.close()

    os.system('sgsim.exe sgsim.par')
    sim_array = GSLIB2ndarray(output_file, 0, nx, ny)
    return (sim_array)


# extract regular spaced samples from a model
def regular_sample(array, xmin, xmax, ymin, ymax, step, mx, my, name):
    x = []
    y = []
    v = []
    iix = 0
    iiy = 0
    xx, yy = np.meshgrid(np.arange(xmin, xmax, step), np.arange(ymax, ymin, -1 * step))
    iiy = 0
    for iy in range(0, my):
        if iiy >= my:
            iix = 0
            for ix in range(0, mx):
                if iix >= mx:
                    x.append(xx[ix, iy]);
                    y.append(yy[ix, iy]);
                    v.append(array[ix, iy])
                    iix = 0;
                    iiy = 0
                iix = iix + 1
        iiy = iiy + 1
    df = pd.DataFrame(np.c_[x, y, v], columns=['X', 'Y', name])
    return (df)

# =============================================================== Begin

os.chdir("D:\Etienne\crmsDATATables")                         # set the working directory

nx = 100; ny = 100; cell_size = 10                             # grid number of cells and cell size
xmin = 0.0
ymin = 0.0                                        # grid origin
xmax = xmin + nx * cell_size
ymax = ymin + ny * cell_size     # calculate the extent of model
seed = 74073                                                   # random number seed  for stochastic simulation
range_max = 1800; range_min = 500; azimuth = 65                # Porosity variogram ranges and azimuth
mean = 10.0; stdev = 2.0                                       # Porosity mean and standard deviation
#cmap = plt.cm.RdYlBu
vmin = 4; vmax = 16; cmap = plt.cm.plasma                      # color min and max and using the plasma color map

# calculate a stochastic realization with standard normal distribution
sim,value = GSLIB_sgsim_2d_uncond(1,nx,ny,cell_size,seed,range_max,range_min,azimuth,"declusTest.csv")
sim = affine(sim,mean,stdev)                                     # correct the distribution to a target mean and standard deviation.



